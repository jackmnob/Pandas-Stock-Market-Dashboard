{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9c1c66-37a9-49b2-9df5-2385db8c2eed",
   "metadata": {},
   "source": [
    "**<span style = \"color:orange;\">Read in the required modules and change our default pandas settings:</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c40bf8-35f9-4652-9053-c871553e3d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules successfully imported!\n"
     ]
    }
   ],
   "source": [
    "#  Use the \"try\" flow control argument to \"try\" and import all of our required modules\n",
    "try:\n",
    "    #  Import basic operating system packages\n",
    "    #  Import os for getting the current working directory\n",
    "    import os\n",
    "    #  Import math and statistics packages\n",
    "    #  Import \"pandas\" for data manipulation and analysis, rename it to \"pd\"\n",
    "    import pandas as pd\n",
    "    #  Import \"numpy\" for numerical computations, rename it to \"np\"\n",
    "    import numpy as np\n",
    "\n",
    "    #  If all module imports are successful print the statement \n",
    "    print('All modules successfully imported!')\n",
    "\n",
    "#  Use an \"except\" clause to escape the \"try\" flow control argument if there is an error - and rename the error to 'moderror'\n",
    "except ModuleNotFoundError as modError:\n",
    "    print(f\"Module failed to import: {modError.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044a34cd-8c52-4c58-bd2f-e9013d47a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display settings successfully applied...\n"
     ]
    }
   ],
   "source": [
    "#  Use the \"try\" flow control argument to \"try\" and change our viewing settings (using pandas/pd) for the IDE\n",
    "try:\n",
    "    # Change pandas default display settings (using pd.set_option()) for JuptyerLab so that our datasets can be fully displayed in our IDE\n",
    "    pd.set_option('display.max_columns', None)   # Ensure we can see all of our data (column-wise)\n",
    "    pd.set_option('display.width', 1000)         # Ensure we can see all of our data (viewing width **None is not a valid parameter**)\n",
    "    pd.set_option('display.max_rows', 50)       # Ensure we can see a large enough sample of our data (300 rows)\n",
    "\n",
    "    # Print our success message for user feedback\n",
    "    print('Display settings successfully applied...')\n",
    "\n",
    "#  Use an \"except\" clause to escape the \"try\" flow control argument if there is an error - and rename the error to 'moderror'\n",
    "except NameError:\n",
    "    print('Error: Pandas (\\'pd\\') is not defined. Ensure that pandas is imported using: import pandas as pd')\n",
    "\n",
    "#  Use an \"except\" clause to escape the \"try\" flow control argument if there is an error - and rename the error to 'moderror'\n",
    "except AttributeError:\n",
    "    print('Error: \\'pd\\' exists, but isn\\'t recognized as pandas. Please check your import statement and ensure that pandas is installed correctly, and isn\\'t assigned to anything else (variables).')\n",
    "    \n",
    "#  Use an \"except\" clause to escape the \"try\" flow control argument if there is an error - and rename the error to 'moderror'\n",
    "except Exception as ex:\n",
    "    print('Unexpected error: ' + str(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab570d-cba6-4c90-837c-672f5c93c349",
   "metadata": {},
   "source": [
    "**<span style = \"color:Red;\">Initialize our filepaths and locate files:</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c690d02-cdad-4dd0-a112-14015a8a67ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our CSV file paths (Apple, Facebook, Google, NVIDIA, Tesla, and Twitter)\n",
    "appleFilePath = r'C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\rawData\\AAPL.csv'\n",
    "facebookFilePath = r'C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\rawData\\FB.csv'\n",
    "googleFilePath = r'C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\rawData\\GOOGL.csv'\n",
    "nvidiaFilePath = r'C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\rawData\\NVDA.csv'\n",
    "teslaFilePath = r'C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\rawData\\TSLA.csv'\n",
    "twitterFilePath = r'C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\rawData\\TWTR.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b968f3-4fde-4c5e-815f-03ae59feed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have been successfully located...\n"
     ]
    }
   ],
   "source": [
    "# Create a list of our file paths\n",
    "filePathList = [appleFilePath, facebookFilePath, googleFilePath, nvidiaFilePath, teslaFilePath, twitterFilePath]\n",
    "\n",
    "# Loop over each file path in the list,\n",
    "for filePath in (filePathList):\n",
    "    # Now, attempt to locate each file path (using os.path.exists())\n",
    "    if not os.path.exists(filePath):\n",
    "        # Print out an error message for our user if the file path is NOT found (a combo of string and our new 'filePath' variable)\n",
    "        print('Error: ' + filePath + ' not found!' + '\\n')\n",
    "        # If a file is NOT found, break the loop after printing our error message - located on the line above\n",
    "        break\n",
    "# Otherwise (if all files are located),\n",
    "else:\n",
    "    # Print our success message for user feedback\n",
    "    print('All files have been successfully located...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846481c-8010-4dfd-a21f-871f02cd711e",
   "metadata": {},
   "source": [
    "**<span style = \"color:Red;\">Use pandas and our file path variables to read our files, getting each stock's data. Then store this data in new, related variables and dictionaries (***ex: '___Df'***)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "750b6768-3dd2-48fc-bfaf-d8800da61257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple's stock data is now loaded\n",
      "\n",
      "Facebook's stock data is now loaded\n",
      "\n",
      "Google's stock data is now loaded\n",
      "\n",
      "NVIDIA's stock data is now loaded\n",
      "\n",
      "Tesla's stock data is now loaded\n",
      "\n",
      "Twitter's stock data is now loaded\n",
      "\n",
      "All selected datasets are now loaded...\n"
     ]
    }
   ],
   "source": [
    "#  Use the \"try\" flow control argument to \"try\" and read all of our selected files\n",
    "try:\n",
    "    # Use pandas (alias = pd) to read our CSV files, getting our stock data. Then, store this data in new variables for each stock (ex: '___Df')\n",
    "    appleDf = pd.read_csv(appleFilePath)\n",
    "    print(f\"Apple's stock data is now loaded\\n\")\n",
    "    facebookDf = pd.read_csv(facebookFilePath)\n",
    "    print(f\"Facebook's stock data is now loaded\\n\")\n",
    "    googleDf = pd.read_csv(googleFilePath)\n",
    "    print(f\"Google's stock data is now loaded\\n\")\n",
    "    nvidiaDf = pd.read_csv(nvidiaFilePath)\n",
    "    print(f\"NVIDIA's stock data is now loaded\\n\")\n",
    "    teslaDf = pd.read_csv(teslaFilePath)\n",
    "    print(f\"Tesla's stock data is now loaded\\n\")\n",
    "    twitterDf = pd.read_csv(twitterFilePath)\n",
    "    print(f\"Twitter's stock data is now loaded\\n\")\n",
    "\n",
    "    # If all datasets are located and successfully loaded, inform the user with a success message. Otherwise,\n",
    "    print(f\"All selected datasets are now loaded...\")\n",
    "\n",
    "#  Use an \"except\" clause to escape the \"try\" flow control argument if there is an error - and rename the error to 'fileError'\n",
    "except FileNotFoundError as fileError:\n",
    "    # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "    print(f\"Error locating stock data! File cannot be found at path: {fileError.filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b0ecef-b912-412e-9eab-0f8c6aa50d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary's keys are: dict_keys(['Apple', 'Facebook', 'Google', 'NVIDIA', 'Tesla', 'Twitter'])\n"
     ]
    }
   ],
   "source": [
    "# Now, create a list of the selected companies' datasets (dataframes) for ease of analysis\n",
    "dfDict = {'Apple':appleDf, 'Facebook':facebookDf, 'Google':googleDf, 'NVIDIA':nvidiaDf, 'Tesla':teslaDf, 'Twitter':twitterDf}\n",
    "\n",
    "# Here is the keys (company names) for our dictionary, which we will be analyzing. Each key is associated with its company's respective market data (contained via their own individual .CSV files)\n",
    "print('The dictionary\\'s keys are: ' + str(dfDict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d105d-367b-44c2-ab18-6fe5b909b5e4",
   "metadata": {},
   "source": [
    "**<span style = \"color:Yellow;\">Now let's do some EDA and view the top 5 rows in each dataset (*each company*) by looping over our dictionary, leveraging pandas' .head() function</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52dcf0c6-df19-4bcd-b335-3fdad631756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple stock data sample -  top 3 rows: \n",
      "\n",
      "         Date      Open      High       Low     Close  Adj Close     Volume\n",
      "0  1980-12-12  0.513393  0.515625  0.513393  0.513393   0.406782  117258400\n",
      "1  1980-12-15  0.488839  0.488839  0.486607  0.486607   0.385558   43971200\n",
      "2  1980-12-16  0.453125  0.453125  0.450893  0.450893   0.357260   26432000\n",
      "\n",
      "Facebook stock data sample -  top 3 rows: \n",
      "\n",
      "         Date       Open   High        Low      Close  Adj Close     Volume\n",
      "0  2012-05-18  42.049999  45.00  38.000000  38.230000  38.230000  573576400\n",
      "1  2012-05-21  36.529999  36.66  33.000000  34.029999  34.029999  168192700\n",
      "2  2012-05-22  32.610001  33.59  30.940001  31.000000  31.000000  101786600\n",
      "\n",
      "Google stock data sample -  top 3 rows: \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2004-08-19  50.050049  52.082081  48.028027  50.220219  50.220219  44659000\n",
      "1  2004-08-20  50.555557  54.594593  50.300301  54.209209  54.209209  22834300\n",
      "2  2004-08-23  55.430431  56.796795  54.579578  54.754753  54.754753  18256100\n",
      "\n",
      "NVIDIA stock data sample -  top 3 rows: \n",
      "\n",
      "         Date      Open      High       Low     Close  Adj Close      Volume\n",
      "0  1999-01-22  1.750000  1.953125  1.552083  1.640625   1.509998  67867200.0\n",
      "1  1999-01-25  1.770833  1.833333  1.640625  1.812500   1.668188  12762000.0\n",
      "2  1999-01-26  1.833333  1.869792  1.645833  1.671875   1.538759   8580000.0\n",
      "\n",
      "Tesla stock data sample -  top 3 rows: \n",
      "\n",
      "         Date       Open   High        Low      Close  Adj Close    Volume\n",
      "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
      "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100\n",
      "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800\n",
      "\n",
      "Twitter stock data sample -  top 3 rows: \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close     Volume\n",
      "0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600\n",
      "1  2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300\n",
      "2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Use the \"try\" flow control argument to \"try\" and print all of our selected companies' stock data\n",
    "try:\n",
    "    # Loop over each item (dataframes/stock data) in our list of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Print our success messages for our user (in this case, the top five rows of each companies' dataset)\n",
    "        # Print the stock name, along with our generic message\n",
    "        print(str(stockName) + ' stock data sample -  top 3 rows: ' + '\\n')\n",
    "        # Print top 5 rows\n",
    "        print(str(df.head(3)) + '\\n')\n",
    "        \n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Close' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "    # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "    print('Error occured while reading dataset: ' + str(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2276d74-eede-4dbd-adf9-338f580e05a9",
   "metadata": {},
   "source": [
    "**<span style = \"color:Purple;\">Create moving averages (new columns) for each company (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cad73ad1-8569-4ce1-9b8c-5e988d9ae50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving averages now added...\n",
      "\n",
      "All columns for Apple are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200'], dtype='object')\n",
      "All columns for Facebook are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200'], dtype='object')\n",
      "All columns for Google are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200'], dtype='object')\n",
      "All columns for NVIDIA are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200'], dtype='object')\n",
      "All columns for Tesla are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200'], dtype='object')\n",
      "All columns for Twitter are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200'], dtype='object')\n",
      "\n",
      "Twitter's dataset with moving averages now included (first 200 rows): \n",
      "\n",
      "           Date       Open       High        Low      Close  Adj Close     Volume     MA50     MA200\n",
      "0    2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600      NaN       NaN\n",
      "1    2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300      NaN       NaN\n",
      "2    2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900      NaN       NaN\n",
      "3    2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700      NaN       NaN\n",
      "4    2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300      NaN       NaN\n",
      "..          ...        ...        ...        ...        ...        ...        ...      ...       ...\n",
      "195  2014-08-19  45.240002  45.450001  45.029999  45.090000  45.090000   11903400  40.2752       NaN\n",
      "196  2014-08-20  44.930000  45.209999  44.759998  45.060001  45.060001   10383200  40.4690       NaN\n",
      "197  2014-08-21  45.290001  45.349998  44.840000  45.110001  45.110001   10619300  40.6604       NaN\n",
      "198  2014-08-22  45.040001  46.139999  44.799999  45.980000  45.980000   19429800  40.8442       NaN\n",
      "199  2014-08-25  46.220001  46.360001  45.700001  46.099998  46.099998   17583500  41.0282  46.45835\n",
      "\n",
      "[200 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "try:\n",
    "    # Loop over each stock (df/dataframe) in our dictionary of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Add a new column for each dataframe (df) called 'MA__' (Moving Average) by using pandas' .rolling() and .mean() functions. A moving average is typically used for the \"Close\" price, so simply access the 'Close' for each df\n",
    "        df['MA50'] = df['Close'].rolling(50).mean()\n",
    "        # Add the 200 day moving average (done by specifying the .rolling() arguement to 200)\n",
    "        df['MA200'] = df['Close'].rolling(200).mean()\n",
    "    \n",
    "    # Print our success message for our user\n",
    "    print('Moving averages now added...' + '\\n')\n",
    "\n",
    "    # Now, loop over each \n",
    "    for stockName, df in dfDict.items():\n",
    "        print('All columns for '+ str(stockName) + ' are: ' + str(df.columns))\n",
    "\n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Close' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "        # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "        print('Warning: ' + str(ex) + ' column not found in one of the datasets!')\n",
    "\n",
    "# View an example of our last stock (Twitter) in the dictionary (dfDict) with the new columns (MA50, MA200) now added\n",
    "print('\\n' + str(list(dfDict.keys())[len(dfDict) - 1]) + \"'s dataset with moving averages now included (first 200 rows): \" + '\\n' + '\\n' + str(dfDict[list(dfDict.keys())[len(dfDict) - 1]].head(200)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147fb35e-d36b-4be5-99af-c4baf3a58132",
   "metadata": {},
   "source": [
    "**<span style = \"color:Purple;\">Create a \"Previous Day Closing Price\" column for each company (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d933fc32-4e12-4123-afa5-cfd6a7cc28b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous day's close prices now added...\n",
      "\n",
      "Now the columns for Apple are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close'], dtype='object')\n",
      "Now the columns for Facebook are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close'], dtype='object')\n",
      "Now the columns for Google are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close'], dtype='object')\n",
      "Now the columns for NVIDIA are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close'], dtype='object')\n",
      "Now the columns for Tesla are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close'], dtype='object')\n",
      "Now the columns for Twitter are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close'], dtype='object')\n",
      "\n",
      "Twitter's dataset with 'Previous Day's Close' now included (first 5 rows): \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close     Volume  MA50  MA200  Previous Days Close\n",
      "0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   NaN    NaN                  NaN\n",
      "1  2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   NaN    NaN            44.900002\n",
      "2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   NaN    NaN            41.650002\n",
      "3  2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   NaN    NaN            42.900002\n",
      "4  2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   NaN    NaN            41.900002\n"
     ]
    }
   ],
   "source": [
    " #  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "try:\n",
    "    # Loop over each stock (df/dataframe) in our dictionary of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Add a new column for each dataframe (df) called 'Previous Day Close' by using pandas' .shift() function.\n",
    "        df['Previous Days Close'] = df['Close'].shift(1)\n",
    "    \n",
    "    # Print our success message for our user\n",
    "    print('Previous day\\'s close prices now added...' + '\\n')\n",
    "\n",
    "    # Now, loop over each \n",
    "    for stockName, df in dfDict.items():\n",
    "        print('Now the columns for '+ str(stockName) + ' are: ' + str(df.columns))\n",
    "\n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Close' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "        # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "        print('Warning: ' + str(ex) + ' column not found in one of the datasets!')\n",
    "\n",
    "# View an example of our last stock (Twitter) in the dictionary (dfDict) with the new column ('Previous day close') now added\n",
    "print('\\n' + str(list(dfDict.keys())[len(dfDict) - 1]) + \"'s dataset with \\'Previous Day's Close' now included (first 5 rows): \" + '\\n' + '\\n' + str(dfDict[list(dfDict.keys())[len(dfDict) - 1]].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59616488-9c57-4cd7-9e1c-5ccfcb7eb1b0",
   "metadata": {},
   "source": [
    "**<span style = \"color:Purple;\">Create a \"Change in Price\" column (Today's Close - Day Before's Close) for each company (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "426765b5-1093-45ab-a6a6-d4065f224e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in price from the previous day is now added...\n",
      "\n",
      "Now the columns for Apple are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price'], dtype='object')\n",
      "Now the columns for Facebook are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price'], dtype='object')\n",
      "Now the columns for Google are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price'], dtype='object')\n",
      "Now the columns for NVIDIA are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price'], dtype='object')\n",
      "Now the columns for Tesla are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price'], dtype='object')\n",
      "Now the columns for Twitter are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price'], dtype='object')\n",
      "\n",
      "Twitter's dataset with 'Change in Price' now included (first 5 rows): \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close     Volume  MA50  MA200  Previous Days Close  Change in Price\n",
      "0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   NaN    NaN                  NaN              NaN\n",
      "1  2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   NaN    NaN            44.900002        -3.250000\n",
      "2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   NaN    NaN            41.650002         1.250000\n",
      "3  2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   NaN    NaN            42.900002        -1.000000\n",
      "4  2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   NaN    NaN            41.900002         0.699997\n"
     ]
    }
   ],
   "source": [
    " #  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "try:\n",
    "    # Loop over each stock (df/dataframe) in our dictionary of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Add a new column for each dataframe (df) called 'Change in Price' by subtracting the 'Previous days Close' from the current 'Close' for the day\n",
    "        df['Change in Price'] = df['Close'] - df['Previous Days Close']\n",
    "    \n",
    "    # Print our success message for our user\n",
    "    print('Change in price from the previous day is now added...' + '\\n')\n",
    "\n",
    "    # Now, loop over each \n",
    "    for stockName, df in dfDict.items():\n",
    "        print('Now the columns for '+ str(stockName) + ' are: ' + str(df.columns))\n",
    "\n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Close' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "        # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "        print('Warning: ' + str(ex) + ' column not found in one of the datasets!')\n",
    "\n",
    "# View an example of our last stock (Twitter) in the dictionary (dfDict) with the new column ('Change in Price') now added\n",
    "print('\\n' + str(list(dfDict.keys())[len(dfDict) - 1]) + \"'s dataset with \\'Change in Price' now included (first 5 rows): \" + '\\n' + '\\n' + str(dfDict[list(dfDict.keys())[len(dfDict) - 1]].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a379f50-c9fe-48e2-acb4-63adf538c0d6",
   "metadata": {},
   "source": [
    "**<span style = \"color:Purple;\">Create a \"% Change in Price\" column ((Today's Close - Day Before's Close) / Day Before's Close) for each company (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0101288d-58fb-4832-9d94-43f9323d40c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Change in Prices is now added...\n",
      "\n",
      "Now the columns for Apple are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price'], dtype='object')\n",
      "Now the columns for Facebook are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price'], dtype='object')\n",
      "Now the columns for Google are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price'], dtype='object')\n",
      "Now the columns for NVIDIA are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price'], dtype='object')\n",
      "Now the columns for Tesla are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price'], dtype='object')\n",
      "Now the columns for Twitter are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price'], dtype='object')\n",
      "\n",
      "Twitter's dataset with '% Change in Price' now included (first 5 rows): \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close     Volume  MA50  MA200  Previous Days Close  Change in Price  % Change in Price\n",
      "0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   NaN    NaN                  NaN              NaN                NaN\n",
      "1  2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   NaN    NaN            44.900002        -3.250000          -0.072383\n",
      "2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   NaN    NaN            41.650002         1.250000           0.030012\n",
      "3  2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   NaN    NaN            42.900002        -1.000000          -0.023310\n",
      "4  2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   NaN    NaN            41.900002         0.699997           0.016706\n"
     ]
    }
   ],
   "source": [
    " #  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "try:\n",
    "    # Loop over each stock (df/dataframe) in our dictionary of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Add a new column for each dataframe (df) called '% Change in Price' by subtracting the current day's close with the previous day's close, then dividing by the previous day's close and multiplying it all by 100 for %\n",
    "        df['% Change in Price'] = ((df['Close'] - df['Previous Days Close']) / df['Previous Days Close'])\n",
    "    \n",
    "    # Print our success message for our user\n",
    "    print('% Change in Prices is now added...' + '\\n')\n",
    "\n",
    "    # Now, loop over each \n",
    "    for stockName, df in dfDict.items():\n",
    "        print('Now the columns for '+ str(stockName) + ' are: ' + str(df.columns))\n",
    "\n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Close' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "        # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "        print('Warning: ' + str(ex) + ' column not found in one of the datasets!')\n",
    "\n",
    "# View an example of our last stock (Twitter) in the dictionary (dfDict) with the new column ('% Change in Price') now added\n",
    "print('\\n' + str(list(dfDict.keys())[len(dfDict) - 1]) + \"'s dataset with \\'% Change in Price' now included (first 5 rows): \" + '\\n' + '\\n' + str(dfDict[list(dfDict.keys())[len(dfDict) - 1]].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fbb85-4043-4138-8552-69c290b7345e",
   "metadata": {},
   "source": [
    "**<span style = \"color:Purple;\">Create a \"Previous Days Volume\" column for each company (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3b787c1-07cc-4af1-8f5a-be4c1de60d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous day's volume is now added...\n",
      "\n",
      "Now the columns for Apple are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume'], dtype='object')\n",
      "Now the columns for Facebook are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume'], dtype='object')\n",
      "Now the columns for Google are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume'], dtype='object')\n",
      "Now the columns for NVIDIA are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume'], dtype='object')\n",
      "Now the columns for Tesla are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume'], dtype='object')\n",
      "Now the columns for Twitter are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume'], dtype='object')\n",
      "\n",
      "Twitter's dataset with 'Previous Days Volume' now included (first 5 rows): \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close     Volume  MA50  MA200  Previous Days Close  Change in Price  % Change in Price  Previous Days Volume\n",
      "0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   NaN    NaN                  NaN              NaN                NaN                   NaN\n",
      "1  2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   NaN    NaN            44.900002        -3.250000          -0.072383           117701600.0\n",
      "2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   NaN    NaN            41.650002         1.250000           0.030012            27925300.0\n",
      "3  2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   NaN    NaN            42.900002        -1.000000          -0.023310            16113900.0\n",
      "4  2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   NaN    NaN            41.900002         0.699997           0.016706             6316700.0\n"
     ]
    }
   ],
   "source": [
    " #  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "try:\n",
    "    # Loop over each stock (df/dataframe) in our dictionary of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Add a new column for each dataframe (df) called 'Previous Days Volume' by using pandas' .shift() function with a value of 1 (indicating the previous day for the calculation)\n",
    "        df['Previous Days Volume'] = df['Volume'].shift(1)\n",
    "\n",
    "    # Print our success message for our user\n",
    "    print('Previous day\\'s volume is now added...' + '\\n')\n",
    "\n",
    "    # Now, loop over each \n",
    "    for stockName, df in dfDict.items():\n",
    "        print('Now the columns for '+ str(stockName) + ' are: ' + str(df.columns))\n",
    "\n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Volume' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "        # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "        print('Warning: ' + str(ex) + ' column not found in one of the datasets!')\n",
    "\n",
    "# View an example of our last stock (Twitter) in the dictionary (dfDict) with the new column ('Previous Days Volume') now added\n",
    "print('\\n' + str(list(dfDict.keys())[len(dfDict) - 1]) + \"'s dataset with \\'Previous Days Volume' now included (first 5 rows): \" + '\\n' + '\\n' + str(dfDict[list(dfDict.keys())[len(dfDict) - 1]].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ad0c1-acd5-441e-92bd-0cad18972df6",
   "metadata": {},
   "source": [
    "**<span style = \"color:Purple;\">Create a \"Change in Volume\" column for each company (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00b027c2-411b-4048-b5fc-ddbad10f33f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in volume from the previous day is now added...\n",
      "\n",
      "Now the columns for Apple are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume'], dtype='object')\n",
      "Now the columns for Facebook are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume'], dtype='object')\n",
      "Now the columns for Google are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume'], dtype='object')\n",
      "Now the columns for NVIDIA are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume'], dtype='object')\n",
      "Now the columns for Tesla are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume'], dtype='object')\n",
      "Now the columns for Twitter are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume'], dtype='object')\n",
      "\n",
      "Twitter's dataset with 'Change in Volume' now included (first 5 rows): \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close     Volume  MA50  MA200  Previous Days Close  Change in Price  % Change in Price  Previous Days Volume  Change in Volume\n",
      "0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   NaN    NaN                  NaN              NaN                NaN                   NaN               NaN\n",
      "1  2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   NaN    NaN            44.900002        -3.250000          -0.072383           117701600.0       -89776300.0\n",
      "2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   NaN    NaN            41.650002         1.250000           0.030012            27925300.0       -11811400.0\n",
      "3  2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   NaN    NaN            42.900002        -1.000000          -0.023310            16113900.0        -9797200.0\n",
      "4  2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   NaN    NaN            41.900002         0.699997           0.016706             6316700.0         2371600.0\n"
     ]
    }
   ],
   "source": [
    " #  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "try:\n",
    "    # Loop over each stock (df/dataframe) in our dictionary of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Add a new column for each dataframe (df) called 'Change in Volume' by subtracting the 'Previous Days Volume' from today's 'Volume'\n",
    "        df['Change in Volume'] = df['Volume'] - df['Previous Days Volume']\n",
    "\n",
    "    # Print our success message for our user\n",
    "    print('Change in volume from the previous day is now added...' + '\\n')\n",
    "\n",
    "    # Now, loop over each \n",
    "    for stockName, df in dfDict.items():\n",
    "        print('Now the columns for '+ str(stockName) + ' are: ' + str(df.columns))\n",
    "\n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Volume' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "        # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "        print('Warning: ' + str(ex) + ' column not found in one of the datasets!')\n",
    "\n",
    "# View an example of our last stock (Twitter) in the dictionary (dfDict) with the new column ('Change in Volume') now added\n",
    "print('\\n' + str(list(dfDict.keys())[len(dfDict) - 1]) + \"'s dataset with \\'Change in Volume' now included (first 5 rows): \" + '\\n' + '\\n' + str(dfDict[list(dfDict.keys())[len(dfDict) - 1]].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52abe3f1-83ab-4a25-9ae0-5e37700a122e",
   "metadata": {},
   "source": [
    "**<span style = \"color:Purple;\">Create a \"% Change in Volume\" column ((Today's Volume - Day Before's Volume) / Day Before's Volume) for each company (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36dd4ea2-2e1b-43bc-b6cb-4f14240d2992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Change in Volume is now added...\n",
      "\n",
      "Now the columns for Apple are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume', '% Change in Volume'], dtype='object')\n",
      "Now the columns for Facebook are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume', '% Change in Volume'], dtype='object')\n",
      "Now the columns for Google are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume', '% Change in Volume'], dtype='object')\n",
      "Now the columns for NVIDIA are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume', '% Change in Volume'], dtype='object')\n",
      "Now the columns for Tesla are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume', '% Change in Volume'], dtype='object')\n",
      "Now the columns for Twitter are: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'MA50', 'MA200', 'Previous Days Close', 'Change in Price', '% Change in Price', 'Previous Days Volume', 'Change in Volume', '% Change in Volume'], dtype='object')\n",
      "\n",
      "Twitter's dataset with '% Change in Price' now included (first 5 rows): \n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close     Volume  MA50  MA200  Previous Days Close  Change in Price  % Change in Price  Previous Days Volume  Change in Volume  % Change in Volume\n",
      "0  2013-11-07  45.099998  50.090000  44.000000  44.900002  44.900002  117701600   NaN    NaN                  NaN              NaN                NaN                   NaN               NaN                 NaN\n",
      "1  2013-11-08  45.930000  46.939999  40.689999  41.650002  41.650002   27925300   NaN    NaN            44.900002        -3.250000          -0.072383           117701600.0       -89776300.0           -0.762745\n",
      "2  2013-11-11  40.500000  43.000000  39.400002  42.900002  42.900002   16113900   NaN    NaN            41.650002         1.250000           0.030012            27925300.0       -11811400.0           -0.422964\n",
      "3  2013-11-12  43.660000  43.779999  41.830002  41.900002  41.900002    6316700   NaN    NaN            42.900002        -1.000000          -0.023310            16113900.0        -9797200.0           -0.607997\n",
      "4  2013-11-13  41.029999  42.869999  40.759998  42.599998  42.599998    8688300   NaN    NaN            41.900002         0.699997           0.016706             6316700.0         2371600.0            0.375449\n"
     ]
    }
   ],
   "source": [
    " #  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "try:\n",
    "    # Loop over each stock (df/dataframe) in our dictionary of selected companies\n",
    "    for stockName, df in (dfDict.items()):\n",
    "        # Add a new column for each dataframe (df) called '% Change in Price' by subtracting the current day's close with the previous day's close, then dividing by the previous day's close and multiplying it all by 100 for %\n",
    "        df['% Change in Volume'] = ((df['Volume'] - df['Previous Days Volume']) / df['Previous Days Volume'])\n",
    "    \n",
    "    # Print our success message for our user\n",
    "    print('% Change in Volume is now added...' + '\\n')\n",
    "\n",
    "    # Now, loop over each \n",
    "    for stockName, df in dfDict.items():\n",
    "        print('Now the columns for '+ str(stockName) + ' are: ' + str(df.columns))\n",
    "\n",
    "# Use an \"except\" clause to escape the \"try\" flow control argument if there is an error with our 'Close' column (or any other columns). If there is, rename the KeyError error to just 'ex'\n",
    "except KeyError as ex:\n",
    "        # Print out the error message for our user (a combo of string and our new exception variable 'ex')\n",
    "        print('Warning: ' + str(ex) + ' column not found in one of the datasets!')\n",
    "\n",
    "# View an example of our last stock (Twitter) in the dictionary (dfDict) with the new column ('% Change in Price') now added\n",
    "print('\\n' + str(list(dfDict.keys())[len(dfDict) - 1]) + \"'s dataset with \\'% Change in Price' now included (first 5 rows): \" + '\\n' + '\\n' + str(dfDict[list(dfDict.keys())[len(dfDict) - 1]].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f50d9f-3f0d-4ac4-977d-4a3f7a17d4ef",
   "metadata": {},
   "source": [
    "**<span style = \"color:Red;\">Now, save our datasets with the new changes (*by looping over a list of the selected dataframes*)</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2634706f-6e5c-4479-bb63-5bc4061aefc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path you have selected for saving is now: C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to save our upcoming CSV file to (in this case, inside our 'Projects' folder)\n",
    "savePath = r'C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData'\n",
    "\n",
    "print('The path you have selected for saving is now: ' + savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a62f8b94-c817-4346-aa67-595900b01262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved Apple.csv to: C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData\n",
      "Successfully saved Facebook.csv to: C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData\n",
      "Successfully saved Google.csv to: C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData\n",
      "Successfully saved NVIDIA.csv to: C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData\n",
      "Successfully saved Tesla.csv to: C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData\n",
      "Successfully saved Twitter.csv to: C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData\n",
      "\n",
      "All files sucessfully saved to C:\\Users\\jackn\\Desktop\\Projects\\Tableau\\Python Manipulation\\cleanData...\n"
     ]
    }
   ],
   "source": [
    "# If the specified savePath (directory) does NOT exist,\n",
    "if not os.path.exists(savePath):\n",
    "    # Give the user an error message indicating that the specified 'savePath' does not currently exist\n",
    "    print('Error: Save directory ' + savePath + ' not found!' + '\\n')\n",
    "# If the specified savePath (directory) does actually exist - then proceed with trying to save all the data to .CSV files,\n",
    "else:\n",
    "     \n",
    "    #  Use the \"try\" flow control argument to \"try\" and loop over all of our selected dataframes (stock data)\n",
    "    try:\n",
    "        # Loop over each stock/company (df/dataframe) in our dictionary of selected companies\n",
    "        for stockName, df in dfDict.items():\n",
    "            # Save each stock/company's dataframe (e.g., 'AAPL') from the dictionary to a .CSV file, at our specified 'savePath' (set index == False to disable the zero-based index column)\n",
    "            dfDict[stockName].to_csv(savePath + '\\\\' + stockName + '.csv', index=False)\n",
    "            # Print our success message for our user (for the individual file)\n",
    "            print('Successfully saved ' + stockName + '.csv to: ' + savePath)\n",
    "        \n",
    "        # Print our final successs message for our user (if ALL files were successfully saved)\n",
    "        print('\\n' + 'All files sucessfully saved to ' + savePath + '...')\n",
    "    # If there are any errors with user permissions for saving within the selected directory,\n",
    "    except PermissionError:\n",
    "        # Print a 'Permission Denied' error message\n",
    "        print('Permission denied. Unable to save files in: ' + savePath + ' - check folder for permissions...')\n",
    "    # If any other general errors occur,\n",
    "    except Exception as ex:\n",
    "        # Give the user a generic error message\n",
    "        print('Error saving file: ' + str(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c584cb-429c-4dfc-be87-e71e84946332",
   "metadata": {},
   "source": [
    "**<span style = \"color:Orange;\">Now, let's proceed over to Tableau with our new CSVs to create some interactive visualizations</span>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
